{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "name": "Dog_Vision_Transfer_Learning.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ahmad1jalal/ML_Projects/blob/main/Dog_Vision_Transfer_Learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YZHyaMxv6WA0"
      },
      "source": [
        "# Import TF 2.x\n",
        "try:\n",
        "  # %tensorflow_version only exists in Colab\n",
        "  %tensorflow_version 2.x\n",
        "except Exception:\n",
        "  pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wJ325_fg7QZg"
      },
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "\n",
        "print(\"TF version:\", tf.__version__)\n",
        "print(\"Hub version:\", hub.__version__)\n",
        "\n",
        "# Check for GPU\n",
        "print(\"GPU\", \"available (YESS!!!!)\" if tf.config.list_physical_devices(\"GPU\") else \"not available :(\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jWlN4oD4FXrz"
      },
      "source": [
        "# Running this cell will provide you with a token to link your drive to this notebook\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9N2BLsAhFnlV"
      },
      "source": [
        "# Use the '-d' parameter as the destination for where the files should go\n",
        "#!unzip \"drive/My Drive/Data/dog-breed-identification.zip\" -d \"drive/My Drive/Data/\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lv1Ayf1qGrI6"
      },
      "source": [
        "# Checkout the labels of our data\n",
        "import pandas as pd\n",
        "labels_csv = pd.read_csv(\"drive/My Drive/Dog Vision/labels.csv\")\n",
        "print(labels_csv.describe())\n",
        "print(labels_csv.head())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "04sOtsyUHduj"
      },
      "source": [
        "Looking at this, we can see there are 10222 different ID's (meaning 10222 different images) and 120 different breeds.\n",
        "\n",
        "Let's figure out how many images there are of each breed."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jfH_jx6lIZbF"
      },
      "source": [
        "# How many images are there of each breed?\n",
        "labels_csv[\"breed\"].value_counts().plot.bar(figsize=(20, 10));"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0wt_Vy3BKfjI"
      },
      "source": [
        "# For getting the images....\n",
        "from IPython.display import display, Image\n",
        "Image(\"drive/My Drive/Dog Vision/train/000bec180eb18c7604dcecc8fe0dba07.jpg\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v7fpANVoRnGr"
      },
      "source": [
        "# Create pathnames from image ID's\n",
        "filenames = [\"drive/My Drive/Dog Vision/train/\" + fname + \".jpg\" for fname in labels_csv[\"id\"]]\n",
        "\n",
        "# Check the first 10 filenames\n",
        "filenames[:10]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zX1Ll_QbR9sF"
      },
      "source": [
        "# As we have got a list of all the filenames from the ID column of `labels_csv`, we can compare it to the number of files in our training data directory to see if they line up.\n",
        "# Check whether number of filenames matches number of actual image files\n",
        "import os\n",
        "if len(os.listdir(\"drive/My Drive/Dog Vision/train/\")) == len(filenames):\n",
        "  print(\"Filenames match with total amount of files!\")\n",
        "else:\n",
        "  print(\"Filenames do not match with actual amount of files, check the target directory.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JbzZjkoKS9u0"
      },
      "source": [
        "# Check an image directly from a filepath\n",
        "Image(filenames[4000])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H9pYpJBpTD7w"
      },
      "source": [
        "import numpy as np\n",
        "labels = labels_csv[\"breed\"].to_numpy() # convert labels column to NumPy array\n",
        "labels[:10]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9P0InW71TmIQ"
      },
      "source": [
        "# Checking if number of labels matches the number of filenames\n",
        "if len(labels) == len(filenames):\n",
        "  print(\"Number of labels matches number of filenames!\")\n",
        "else:\n",
        "  print(\"Number of labels does not match number of filenames, check data directories.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5K6Oul0uUq4f"
      },
      "source": [
        "# Find the unique label values\n",
        "unique_breeds = np.unique(labels)\n",
        "len(unique_breeds)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4lDpNHTpU0WN"
      },
      "source": [
        "# Example: Turn one label into an array of booleans\n",
        "print(labels[0])\n",
        "labels[0] == unique_breeds # use comparison operator to create boolean array"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Iq3n1SzVVk_"
      },
      "source": [
        "# Turning  every label into a boolean\n",
        "boolean_labels = [label == np.array(unique_breeds) for label in labels]\n",
        "boolean_labels[:2]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O4nTwfC9WDn7"
      },
      "source": [
        "# Example: Turning a boolean array into integers\n",
        "print(labels[0]) # original label\n",
        "print(np.where(unique_breeds == labels[0])[0][0]) # index where label occurs\n",
        "print(boolean_labels[0].argmax()) # index where label occurs in boolean array\n",
        "print(boolean_labels[0].astype(int)) # there will be a 1 where the sample label occurs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ylTZ5QsV8jyX"
      },
      "source": [
        "# Setup X & y variables\n",
        "X = filenames\n",
        "y = boolean_labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-iUUiacU_8ey"
      },
      "source": [
        "# Set number of images to use for experimenting\n",
        "NUM_IMAGES = 1000 #@param {type:\"slider\", min:1000, max:10000, step:1000}\n",
        "NUM_IMAGES"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s6RNwMv3BD7N"
      },
      "source": [
        "# Splitting train and test data\n",
        "# it is a best idea to have a 80% in training and 20% in testing\n",
        "# Import train_test_split from Scikit-Learn\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Split them into training and validation using NUM_IMAGES \n",
        "X_train, X_val, y_train, y_val = train_test_split(X[:NUM_IMAGES],\n",
        "                                                  y[:NUM_IMAGES], \n",
        "                                                  test_size=0.2,\n",
        "                                                  random_state=42)\n",
        "\n",
        "len(X_train), len(y_train), len(X_val), len(y_val)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gVw0TrUQCfDa"
      },
      "source": [
        "# Check out the training data (image file paths and labels)\n",
        "X_train[:5], y_train[:2]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cvq4aLj8D_yX"
      },
      "source": [
        "# Convert image to NumPy array\n",
        "from matplotlib.pyplot import imread\n",
        "image = imread(filenames[42]) # read in an image\n",
        "image.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4WvOdwIcG3eS"
      },
      "source": [
        "tf.constant(image)[:2]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ezyHapaOG48I"
      },
      "source": [
        "# Define image size\n",
        "IMG_SIZE = 224\n",
        "\n",
        "def process_image(image_path):\n",
        "  \"\"\"\n",
        "  Takes an image file path and turns it into a Tensor.\n",
        "  \"\"\"\n",
        "  # Read in image file\n",
        "  image = tf.io.read_file(image_path)\n",
        "  # Turn the jpeg image into numerical Tensor with 3 colour channels (Red, Green, Blue)\n",
        "  image = tf.image.decode_jpeg(image, channels=3)\n",
        "  # Convert the colour channel values from 0-225 values to 0-1 values\n",
        "  image = tf.image.convert_image_dtype(image, tf.float32)\n",
        "  # Resize the image to our desired size (224, 244)\n",
        "  image = tf.image.resize(image, size=[IMG_SIZE, IMG_SIZE])\n",
        "  return image"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KXSG48e9PCAX"
      },
      "source": [
        "# Create a simple function to return a tuple (image, label)\n",
        "def get_image_label(image_path, label):\n",
        "  \"\"\"\n",
        "  Takes an image file path name and the associated label,\n",
        "  processes the image and returns a tuple of (image, label).\n",
        "  \"\"\"\n",
        "  image = process_image(image_path)\n",
        "  return image, label"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VNACj1SO-RpY"
      },
      "source": [
        "\n",
        "# Define the batch size, 32 is a good default because According to Yann LeCun it is a best practice to use 32 size\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "# Create a function to turn data into batches\n",
        "def create_data_batches(x, y=None, batch_size=BATCH_SIZE, valid_data=False, test_data=False):\n",
        "  \"\"\"\n",
        "  Creates batches of data out of image (x) and label (y) pairs.\n",
        "  Shuffles the data if it's training data but doesn't shuffle it if it's validation data.\n",
        "  Also accepts test data as input (no labels).\n",
        "  \"\"\"\n",
        "  # If the data is a test dataset, we probably don't have labels\n",
        "  if test_data:\n",
        "    print(\"Creating test data batches...\")\n",
        "    data = tf.data.Dataset.from_tensor_slices((tf.constant(x))) # only filepaths\n",
        "    data_batch = data.map(process_image).batch(BATCH_SIZE)\n",
        "    return data_batch\n",
        "  \n",
        "  # If the data if a valid dataset, we don't need to shuffle it\n",
        "  elif valid_data:\n",
        "    print(\"Creating validation data batches...\")\n",
        "    data = tf.data.Dataset.from_tensor_slices((tf.constant(x), # filepaths\n",
        "                                               tf.constant(y))) # labels\n",
        "    data_batch = data.map(get_image_label).batch(BATCH_SIZE)\n",
        "    return data_batch\n",
        "\n",
        "  else:\n",
        "    # If the data is a training dataset, we shuffle it\n",
        "    print(\"Creating training data batches...\")\n",
        "    # Turn filepaths and labels into Tensors\n",
        "    data = tf.data.Dataset.from_tensor_slices((tf.constant(x), # filepaths\n",
        "                                              tf.constant(y))) # labels\n",
        "    \n",
        "    # Shuffling pathnames and labels before mapping image processor function is faster than shuffling images\n",
        "    data = data.shuffle(buffer_size=len(x))\n",
        "\n",
        "    # Create (image, label) tuples (this also turns the image path into a preprocessed image)\n",
        "    data = data.map(get_image_label)\n",
        "\n",
        "    # Turn the data into batches\n",
        "    data_batch = data.batch(BATCH_SIZE)\n",
        "  return data_batch"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-K7GbSTZMFgL"
      },
      "source": [
        "# Create training and validation data batches\n",
        "train_data = create_data_batches(X_train, y_train)\n",
        "val_data = create_data_batches(X_val, y_val, valid_data=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ya6gI9ImMeBq"
      },
      "source": [
        "# Check out the different attributes of our data batches\n",
        "train_data.element_spec, val_data.element_spec"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ou_fRHK2JMca"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Create a function for viewing images in a data batch\n",
        "def show_25_images(images, labels):\n",
        "  \"\"\"\n",
        "  Displays 25 images from a data batch.\n",
        "  \"\"\"\n",
        "  # Setup the figure\n",
        "  plt.figure(figsize=(10, 10))\n",
        "  # Loop through 25 (for displaying 25 images)\n",
        "  for i in range(25):\n",
        "    # Create subplots (5 rows, 5 columns)\n",
        "    ax = plt.subplot(5, 5, i+1)\n",
        "    # Display an image\n",
        "    plt.imshow(images[i])\n",
        "    # Add the image label as the title\n",
        "    plt.title(unique_breeds[labels[i].argmax()])\n",
        "    # Turn gird lines off\n",
        "    plt.axis(\"off\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KpNpypPuL_IJ"
      },
      "source": [
        "# Visualize training images from the training data batch\n",
        "train_images, train_labels = next(train_data.as_numpy_iterator())\n",
        "show_25_images(train_images, train_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wlnzt9mkN4n5"
      },
      "source": [
        "# Visualize validation images from the validation data batch\n",
        "val_images, val_labels = next(val_data.as_numpy_iterator())\n",
        "show_25_images(val_images, val_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J90ZIz7ZUgej"
      },
      "source": [
        "# Setup input shape to the model\n",
        "INPUT_SHAPE = [None, IMG_SIZE, IMG_SIZE, 3] # batch, height, width, colour channels\n",
        "\n",
        "# Setup output shape of the model\n",
        "OUTPUT_SHAPE = len(unique_breeds) # number of unique labels\n",
        "\n",
        "# Setup model URL from TensorFlow Hub\n",
        "MODEL_URL = \"https://tfhub.dev/google/imagenet/mobilenet_v2_130_224/classification/4\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sjYKUMTWSmbB"
      },
      "source": [
        "# Create a function which builds a Keras model\n",
        "def create_model(input_shape=INPUT_SHAPE, output_shape=OUTPUT_SHAPE, model_url=MODEL_URL):\n",
        "  print(\"Building model with:\", MODEL_URL)\n",
        "\n",
        "  # Setup the model layers\n",
        "  model = tf.keras.Sequential([\n",
        "    hub.KerasLayer(MODEL_URL), # Layer 1 (input layer)\n",
        "    tf.keras.layers.Dense(units=OUTPUT_SHAPE, \n",
        "                          activation=\"softmax\") # Layer 2 (output layer)\n",
        "  ])\n",
        "\n",
        "  # Compile the model\n",
        "  model.compile(\n",
        "      loss=tf.keras.losses.CategoricalCrossentropy(), # Our model wants to reduce this (how wrong its guesses are)\n",
        "      optimizer=tf.keras.optimizers.Adam(), # A friend telling our model how to improve its guesses\n",
        "      metrics=[\"accuracy\"] # We'd like this to go up\n",
        "  )\n",
        "\n",
        "  # Build the model\n",
        "  model.build(INPUT_SHAPE) # Let the model know what kind of inputs it'll be getting\n",
        "  \n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y3_vCn0ZSj5M"
      },
      "source": [
        "# Create a model and check its details\n",
        "model = create_model()\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TmIBcrkRSixu"
      },
      "source": [
        "# Load the TensorBoard notebook extension\n",
        "%load_ext tensorboard"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hT94y1375t76"
      },
      "source": [
        "import datetime\n",
        "\n",
        "# Create a function to build a TensorBoard callback\n",
        "def create_tensorboard_callback():\n",
        "  # Create a log directory for storing TensorBoard logs\n",
        "  logdir = os.path.join(\"drive/My Drive/Data/logs\",\n",
        "                        # Make it so the logs get tracked whenever we run an experiment\n",
        "                        datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
        "  return tf.keras.callbacks.TensorBoard(logdir)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BD6bvwx26pE4"
      },
      "source": [
        "# Create early stopping (once our model stops improving, stop training)\n",
        "early_stopping = tf.keras.callbacks.EarlyStopping(monitor=\"val_accuracy\",\n",
        "                                                  patience=3) # stops after 3 rounds of no improvements"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I810g3EjSiTx"
      },
      "source": [
        "# Check again if GPU is available (otherwise computing will take a looooonnnnggggg time)\n",
        "print(\"GPU\", \"available (YESS!!!!)\" if tf.config.list_physical_devices(\"GPU\") else \"not available :(\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GFe7tira73It"
      },
      "source": [
        "# How many rounds should we get the model to look through the data?\n",
        "NUM_EPOCHS = 100 #@param {type:\"slider\", min:10, max:100, step:10}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sVG2q8Ep-ewd"
      },
      "source": [
        "# Build a function to train and return a trained model\n",
        "def train_model():\n",
        "  \"\"\"\n",
        "  Trains a given model and returns the trained version.\n",
        "  \"\"\"\n",
        "  # Create a model\n",
        "  model = create_model()\n",
        "\n",
        "  # Create new TensorBoard session everytime we train a model\n",
        "  tensorboard = create_tensorboard_callback()\n",
        "\n",
        "  # Fit the model to the data passing it the callbacks we created\n",
        "  model.fit(x=train_data,\n",
        "            epochs=NUM_EPOCHS,\n",
        "            validation_data=val_data,\n",
        "            validation_freq=1, # check validation metrics every epoch\n",
        "            callbacks=[tensorboard, early_stopping])\n",
        "  \n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jEUEsrlvG6Z2"
      },
      "source": [
        "# Turn prediction probabilities into their respective label (easier to understand)\n",
        "def get_pred_label(prediction_probabilities):\n",
        "  \"\"\"\n",
        "  Turns an array of prediction probabilities into a label.\n",
        "  \"\"\"\n",
        "  return unique_breeds[np.argmax(prediction_probabilities)]\n",
        "\n",
        "# Get a predicted label based on an array of prediction probabilities\n",
        "#pred_label = get_pred_label(predictions[0])\n",
        "#pred_label"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NEwoi7sjHdr_"
      },
      "source": [
        "# Create a function to unbatch a batched dataset\n",
        "def unbatchify(data):\n",
        "  \"\"\"\n",
        "  Takes a batched dataset of (image, label) Tensors and returns separate arrays\n",
        "  of images and labels.\n",
        "  \"\"\"\n",
        "  images = []\n",
        "  labels = []\n",
        "  # Loop through unbatched data\n",
        "  for image, label in data.unbatch().as_numpy_iterator():\n",
        "    images.append(image)\n",
        "    labels.append(unique_breeds[np.argmax(label)])\n",
        "  return images, labels\n",
        "\n",
        "# Unbatchify the validation data\n",
        "val_images, val_labels = unbatchify(val_data)\n",
        "val_images[0], val_labels[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5YdcsHKlLMcW"
      },
      "source": [
        "def plot_pred(prediction_probabilities, labels, images, n=1):\n",
        "  \"\"\"\n",
        "  View the prediction, ground truth label and image for sample n.\n",
        "  \"\"\"\n",
        "  pred_prob, true_label, image = prediction_probabilities[n], labels[n], images[n]\n",
        "  \n",
        "  # Get the pred label\n",
        "  pred_label = get_pred_label(pred_prob)\n",
        "  \n",
        "  # Plot image & remove ticks\n",
        "  plt.imshow(image)\n",
        "  plt.xticks([])\n",
        "  plt.yticks([])\n",
        "\n",
        "  # Change the color of the title depending on if the prediction is right or wrong\n",
        "  if pred_label == true_label:\n",
        "    color = \"green\"\n",
        "  else:\n",
        "    color = \"red\"\n",
        "\n",
        "  plt.title(\"{} {:2.0f}% ({})\".format(pred_label,\n",
        "                                      np.max(pred_prob)*100,\n",
        "                                      true_label),\n",
        "                                      color=color)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IsWZOTMZNfha"
      },
      "source": [
        "def plot_pred_conf(prediction_probabilities, labels, n=1):\n",
        "  \"\"\"\n",
        "  Plots the top 10 highest prediction confidences along with\n",
        "  the truth label for sample n.\n",
        "  \"\"\"\n",
        "  pred_prob, true_label = prediction_probabilities[n], labels[n]\n",
        "\n",
        "  # Get the predicted label\n",
        "  pred_label = get_pred_label(pred_prob)\n",
        "\n",
        "  # Find the top 10 prediction confidence indexes\n",
        "  top_10_pred_indexes = pred_prob.argsort()[-10:][::-1]\n",
        "  # Find the top 10 prediction confidence values\n",
        "  top_10_pred_values = pred_prob[top_10_pred_indexes]\n",
        "  # Find the top 10 prediction labels\n",
        "  top_10_pred_labels = unique_breeds[top_10_pred_indexes]\n",
        "\n",
        "  # Setup plot\n",
        "  top_plot = plt.bar(np.arange(len(top_10_pred_labels)), \n",
        "                     top_10_pred_values, \n",
        "                     color=\"grey\")\n",
        "  plt.xticks(np.arange(len(top_10_pred_labels)),\n",
        "             labels=top_10_pred_labels,\n",
        "             rotation=\"vertical\")\n",
        "\n",
        "  # Change color of true label\n",
        "  if np.isin(true_label, top_10_pred_labels):\n",
        "    top_plot[np.argmax(top_10_pred_labels == true_label)].set_color(\"green\")\n",
        "  else:\n",
        "    pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-am2i8nfSok5"
      },
      "source": [
        "def save_model(model, suffix=None):\n",
        "  \"\"\"\n",
        "  Saves a given model in a models directory and appends a suffix (str)\n",
        "  for clarity and reuse.\n",
        "  \"\"\"\n",
        "  # Create model directory with current time\n",
        "  modeldir = os.path.join(\"drive/My Drive/Data/models\",\n",
        "                          datetime.datetime.now().strftime(\"%Y%m%d-%H%M%s\"))\n",
        "  model_path = modeldir + \"-\" + suffix + \".h5\" # save format of model\n",
        "  print(f\"Saving model to: {model_path}...\")\n",
        "  model.save(model_path)\n",
        "  return model_path"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DTsodywBg-yH"
      },
      "source": [
        "def load_model(model_path):\n",
        "  \"\"\"\n",
        "  Loads a saved model from a specified path.\n",
        "  \"\"\"\n",
        "  print(f\"Loading saved model from: {model_path}\")\n",
        "  model = tf.keras.models.load_model(model_path,\n",
        "                                     custom_objects={\"KerasLayer\":hub.KerasLayer})\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1HY1RN2iKvDe"
      },
      "source": [
        "# Create full model callbacks\n",
        "\n",
        "# TensorBoard callback\n",
        "full_model_tensorboard = create_tensorboard_callback()\n",
        "\n",
        "# Early stopping callback\n",
        "# Note: No validation set when training on all the data, therefore can't monitor validation accruacy\n",
        "#full_model_early_stopping = tf.keras.callbacks.EarlyStopping(monitor=\"accuracy\",\n",
        "                                                             patience=3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dARUFZx35bwU"
      },
      "source": [
        "full_data = create_data_batches(X, y)\n",
        "# Instantiate a new model for training on the full dataset\n",
        "full_model = create_model()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8F0IjHkYJINx"
      },
      "source": [
        "# Fit the full model to the full training data\n",
        "full_model.fit(x=full_data,\n",
        "               epochs=NUM_EPOCHS,\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uK0CH96CMx17"
      },
      "source": [
        "### Saving and reloading the full model\n",
        "\n",
        "Even on a GPU, our full model took a while to train. So it's a good idea to save it.\n",
        "\n",
        "We can do so using our `save_model()` function.\n",
        "\n",
        "**Challenge:** It may be a good idea to incorporate the `save_model()` function into a `train_model()` function. Or look into setting up a [checkpoint callback](https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/ModelCheckpoint)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2TSB2BlbJI6o"
      },
      "source": [
        "# Save model to file\n",
        "save_model(full_model, suffix=\"all-images-Adam\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XU50x9_ud_8h"
      },
      "source": [
        "# Load in the full model\n",
        "loaded_full_model = load_model('drive/My Drive/Data/models/20200131-03111580440309-all-images-Adam.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KbZIu7gsSOnl"
      },
      "source": [
        "### Making predictions on the test dataset\n",
        "\n",
        "Since our model has been trained on images in the form of Tensor batches, to make predictions on the test data, we'll have to get it into the same format.\n",
        "\n",
        "Luckily we created `create_data_batches()` earlier which can take a list of filenames as input and convert them into Tensor batches.\n",
        "\n",
        "To make predictions on the test data, we'll:\n",
        "* Get the test image filenames.\n",
        "* Convert the filenames into test data batches using `create_data_batches()` and setting the `test_data` parameter to `True` (since there are no labels with the test images).\n",
        "* Make a predictions array by passing the test data batches to the `predict()` function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LSsfWC7seJTu"
      },
      "source": [
        "# Load test image filenames (since we're using os.listdir(), these already have .jpg)\n",
        "test_path = \"drive/My Drive/Data/test/\"\n",
        "test_filenames = [test_path + fname for fname in os.listdir(test_path)]\n",
        "\n",
        "test_filenames[:10]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FAk4DZcH9VNK"
      },
      "source": [
        "# How many test images are there?\n",
        "len(test_filenames)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WWzszs_jeSax"
      },
      "source": [
        "# Create test data batch\n",
        "test_data = create_data_batches(test_filenames, test_data=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "noMTOLG0I09w"
      },
      "source": [
        "**Note:** Since there are 10,000+ test images, making predictions could take a while, even on a GPU. So beware running the cell below may take up to an hour."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QYdzux9IeUtf"
      },
      "source": [
        "# Make predictions on test data batch using the loaded full model\n",
        "test_predictions = loaded_full_model.predict(test_data,\n",
        "                                             verbose=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9CIvLI6xeZEl"
      },
      "source": [
        "# Check out the test predictions\n",
        "test_predictions[:10]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IK7LK91wEN6d"
      },
      "source": [
        "# Get custom image filepaths\n",
        "custom_path = \"drive/My Drive/Dog Vision/dogs/\"\n",
        "custom_image_paths = [custom_path + fname for fname in os.listdir(custom_path)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3GPFBd5Re_Lu"
      },
      "source": [
        "# Turn custom image into batch (set to test data because there are no labels)\n",
        "custom_data = create_data_batches(custom_image_paths, test_data=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_lQkS5LvHU_S"
      },
      "source": [
        "# Make predictions on the custom data\n",
        "custom_preds = loaded_full_model.predict(custom_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5RnKJG2LJDb4"
      },
      "source": [
        "Now we've got some predictions arrays, let's convert them to labels and compare them with each image."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3tKMRvSlHdtZ"
      },
      "source": [
        "# Get custom image prediction labels\n",
        "custom_pred_labels = [get_pred_label(custom_preds[i]) for i in range(len(custom_preds))]\n",
        "custom_pred_labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h7ijs_yVJ8k2"
      },
      "source": [
        "# Get custom images (our unbatchify() function won't work since there aren't labels)\n",
        "custom_images = []\n",
        "# Loop through unbatched data\n",
        "for image in custom_data.unbatch().as_numpy_iterator():\n",
        "  custom_images.append(image)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "boYG1SFSKbTH"
      },
      "source": [
        "# Check custom image predictions\n",
        "plt.figure(figsize=(10, 10))\n",
        "for i, image in enumerate(custom_images):\n",
        "  plt.subplot(1, 3, i+1)\n",
        "  plt.xticks([])\n",
        "  plt.yticks([])\n",
        "  plt.title(custom_pred_labels[i])\n",
        "  plt.imshow(image)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}